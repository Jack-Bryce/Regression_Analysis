{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "7Ixx08y81PAv",
        "MxtTI5685A1A",
        "4r0CcArBLIhj"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Introduction + Problem Definition\n",
        "The data that is used for this coursework is a dataset about the bike rentals for a bike sharing system between 2011 and 2012 which allows users to rent a bike and return them to particular station. Whilst there are multiple systems out there they have many real world benefits and applications, the data that can be (and has been) collected can be used analyse the conditions for which people will rent these systems bikes.\n",
        "\n",
        "In this instance of the dataset, one group of columns/attributes that has been collected is the number of bike rentals as well as the total number of rentals split by the type of renter (a casual user or a member for the system).\n",
        "\n",
        "This information alongside the day and hour columns allows the analyst to identify the peak rental times of the bikes and allows for the analyst to forecast the number of bikes in use at a given time.\n",
        "\n",
        "Beyond the season, date, year, month and hours, the dataset also contains the information on whether it is a working day, weekday or a holiday or not. This allows for an extra level of exploration for the analyst as they can focus on a particular kind of day as well as having another dimension to analyse the peak times.\n",
        "\n",
        "The dataset also contains information on the type of weather for the particular day and hour. Furthermore it contains information about the normalized temperature (as well as the temperature it feels like both in celsius), humidity and windspeed. These columns allow for the analyst to explore the affects of the weather on the number of bike rentals.\n",
        "\n",
        "The prediction of the number of bike rentals is a regression problem because the models the make the predictions are identifying the relationships between the input variables and the target variable (bike rentals). This relationship is used to predict the number of bike rentals using the given linear equation (Linear Regression) or conditions (Decision Tree) of the model.\n",
        "\n",
        "The question that is being asked is how the 2 temperatures, whether it is a holiday or working day, whether or not it is a peak rental time or whether it is the night time. "
      ],
      "metadata": {
        "id": "gtwmY0w6fhN_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Ingestion + Importing Libraries\n",
        "Import the necessary libraries and mount the notebook on the google drive containing the data."
      ],
      "metadata": {
        "id": "oSzOm4z4tMci"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-HLm3lgSa3D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad1b58c5-3387-4713-8207-15f8880e574c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd\n",
        "import sklearn.preprocessing\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "path = \"/content/gdrive/My Drive/DW_data/\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After the notebook has been mounted on the google drive, we will need to load the dataset into a dataframe."
      ],
      "metadata": {
        "id": "T59nC9sHzGdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Read the bike data from the csv file.\n",
        "df = pd.read_csv(path+\"bike-dataset hour.csv\")"
      ],
      "metadata": {
        "id": "AyIRFhX6V3lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preparation\n",
        "Before implementing the preparation of the data, there will be a description of the statistical data types for each of the columns of the dataset. Firstly, the temp, atemp, hum(idity), and windspeed columns are all continuous values as they are decimal values between 0 and 1.\n",
        "\n",
        "Next, the dteday, season, year, month, hr and instant columns are all Ordinal data types as they are discretized (distinct labels/buckets) that have some notion of order. For example, the hour columns order is from the first hour (0) to the last hour (23).\n",
        "\n",
        "The weathersit, holdiay, weekday and workingday columns are all Nominal data types as each value/label represents a category. One example of this is the workingday column's values of No and Yes. These values put labels to whether or not it is a daythat people work or not.\n",
        "\n",
        "The casual, registered and cnt (total number of rentals) are Numerical data types. These columns describe how many rentals their has been as well as how many rentals there has been by casual and registered users. These values are continuous, but cannot be decimal values due to the fact that a user cannot have a fraction of a rental.\n",
        "\n",
        "The first step is to find the appropriate replacement values for the nan values in temp and atemp. To do this we will find the average value for each hour that we have a nan value for and then replace it with that average.\n",
        "\n",
        "The use of the invalid row's respective hour is because the peak rental times will be accounted for in these averages."
      ],
      "metadata": {
        "id": "7Ixx08y81PAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Iterate over the dataset and add the values together (categorized by the hour they are in).\n",
        "hs_temp, hs_count = [0.0 for i in range(24)], [0 for i in range(24)] \n",
        "for h, t in zip(df['hr'], df['temp']):\n",
        "  if math.isnan(t) == False:\n",
        "    hs_temp[h] += t\n",
        "    hs_count[h] += 1\n",
        "\n",
        "#Divide hs_temp by hs_count.\n",
        "hs_temp, hs_count = np.array(hs_temp), np.array(hs_count)\n",
        "hs_temp_mean = hs_temp / hs_count\n",
        "\n",
        "#Do the same as the above but for the atemp attribute of the dataset.\n",
        "hs_atemp, hs_count = [0.0 for i in range(24)], [0 for i in range(24)] \n",
        "for h, t in zip(df['hr'], df['atemp']):\n",
        "  if math.isnan(t) == False:\n",
        "    hs_atemp[h] += t\n",
        "    hs_count[h] += 1\n",
        "\n",
        "#Divide hs_atemp by hs_count.\n",
        "hs_atemp, hs_count = np.array(hs_atemp), np.array(hs_count)\n",
        "hs_atemp_mean = hs_atemp / hs_count"
      ],
      "metadata": {
        "id": "IO0jsDjL2LDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the mean values of temp and atemp (split across each hour), we will now replace the nan values with the appropriate hour."
      ],
      "metadata": {
        "id": "WTWefu1lK57m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This replaces the nan values with the average.\n",
        "for i in range(len(df['temp'])):\n",
        "  #Handle the temp attribute if the value is nan.\n",
        "  if math.isnan(df['temp'][i]):\n",
        "    df['temp'][i] = hs_temp_mean[df['hr'][i]]\n",
        "\n",
        "  #Handle the atemp attribute if the value is nan.\n",
        "  if math.isnan(df['atemp'][i]):\n",
        "    df['atemp'][i] = hs_atemp_mean[df['hr'][i]]"
      ],
      "metadata": {
        "id": "ZNARwTj3LJIU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7770d6b-4e00-458b-f94c-9606bae2c297"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-292c961b6f70>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['temp'][i] = hs_temp_mean[df['hr'][i]]\n",
            "<ipython-input-9-292c961b6f70>:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['atemp'][i] = hs_atemp_mean[df['hr'][i]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next step is to remove the redundant attributes like dedate, yr and day. "
      ],
      "metadata": {
        "id": "kxQ3Fq7Y2RRP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['hr', 'holiday', 'workingday', 'cnt', 'weathersit', 'temp', 'atemp']]"
      ],
      "metadata": {
        "id": "AfdBqBt82ag2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we will find the periods that are the peak times and when it is night time."
      ],
      "metadata": {
        "id": "ko30tgYT1evl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create these columns within the dataframe so the peaktimes and nighttimes can be identified and stored.\n",
        "df['peaktimes'] = [0 for _ in range(len(df['hr']))]\n",
        "df['nighttime'] = [0 for _ in range(len(df['hr']))]\n",
        "\n",
        "#Find the appropriate labels for the new columns for each entry.\n",
        "for i in range(len(df['workingday'])):\n",
        "  #This checks for the peak times for the working days.\n",
        "  if df['workingday'][i] == \"Yes\":\n",
        "    if (df['hr'][i] >= 7 and df['hr'][i] <= 9) or (df['hr'][i] >= 16 and df['hr'][i] <= 19):\n",
        "      df['peaktimes'][i] = 1\n",
        "    else:\n",
        "      df['peaktimes'][i] = 0\n",
        "  \n",
        "  #This checks for the peak times when they are not working.\n",
        "  if df['workingday'][i] == \"No\":\n",
        "    if df['hr'][i] >= 10 and df['hr'][i] <= 16:\n",
        "      df['peaktimes'][i] = 1\n",
        "    else:\n",
        "      df['peaktimes'][i] = 0\n",
        "\n",
        "  #This checks the periods that are considered to be the night.\n",
        "  if df['hr'][i] >= 22 or df['hr'][i] <= 4:\n",
        "    df['nighttime'][i] = 1\n",
        "  else:\n",
        "    df['nighttime'][i] = 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Knpv035g1eKU",
        "outputId": "274b81fb-b6b6-4966-e928-84a96bdb4ff7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-13d676ed5708>:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['peaktimes'][i] = 0\n",
            "<ipython-input-11-13d676ed5708>:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['nighttime'][i] = 1\n",
            "<ipython-input-11-13d676ed5708>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['nighttime'][i] = 0\n",
            "<ipython-input-11-13d676ed5708>:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['peaktimes'][i] = 1\n",
            "<ipython-input-11-13d676ed5708>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['peaktimes'][i] = 0\n",
            "<ipython-input-11-13d676ed5708>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['peaktimes'][i] = 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Binning is the process of discretizing a variable in to individual 'buckets'. An example of this would be taking a continuous value such as age and placing them into buckets/brackets such as 18-24, 25-34 all the way to 60+.\n",
        "\n",
        "Given the above paragraph about Data Binning, it would be appropriate to apply this concept to the temp and atemp columns of the dataset. This is because it would allow for the dataset to be split by a Decision Tree whilst also retaining enough of it's linear origin that it can be used by the Linear Regression and other equation based regression models."
      ],
      "metadata": {
        "id": "rfAdrvGm2Otl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following section the data will be encoded to their appropriate types. The temp and atemp columns will be discretized (Data Binning). Each 'bucket' or discretized value for these columns will receive it's own column to reduce these variables into a binary label which would allow for the problem to be more accurate."
      ],
      "metadata": {
        "id": "sd5GJNMT4zwp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Discretize the temp column for the RandomForest method.\n",
        "df.loc[(0.0 <= df['temp']) & (df['temp'] <= 0.1), 'temp'] = 0.0\n",
        "for i in range(1, 10):\n",
        "  df.loc[(i/10 < df['temp']) & (df['temp'] <= (i+1)/10), 'temp'] = float(i)\n",
        "\n",
        "#Discretize the atemp column for the RandomForest method.\n",
        "df.loc[(0.0 <= df['atemp']) & (df['atemp'] <= 0.1), 'atemp'] = 0.0\n",
        "for i in range(1, 10):\n",
        "  df.loc[(i/10 < df['atemp']) & (df['atemp'] <= (i+1)/10), 'atemp'] = float(i)\n",
        "\n",
        "#Convert the above columns back to integers.\n",
        "df['temp'] = [int(t) for t in df['temp'].to_numpy()]\n",
        "df['atemp'] = [int(t) for t in df['atemp'].to_numpy()]\n",
        "\n",
        "#Convert the workingday column to an integer-based binary label\n",
        "df['workingday'] = sklearn.preprocessing.LabelEncoder().fit_transform(df['workingday'])\n",
        "\n",
        "#Given each index (between 0 and 9), split each label into it's own binary classification.\n",
        "n=10\n",
        "for i in range(n):\n",
        "  df['temp_{idx}'.format(idx=i)] = [1 if ((i/n) > df.iloc[j]['temp']) and (df.iloc[j]['temp'] <= (i+1)/n) else 0 for j in range(len(df['temp']))]\n",
        "  df['atemp_{idx}'.format(idx=i)] = [1 if ((i/n) > df.iloc[j]['atemp']) and (df.iloc[j]['atemp'] <= (i+1)/n) else 0 for j in range(len(df['atemp']))]\n",
        "\n",
        "#Now we just need to drop the hr column from the DataFrame.\n",
        "names = [t for t in df if t != 'hr']\n",
        "df = df[names]"
      ],
      "metadata": {
        "id": "aRGt_zSD47S_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Segregation\n",
        "The dataset will have an (80/0/20)% (training/validation/testing) split. This split is used as the choosen methods will benefit from generating a regression model with a larger amount of data from the dataset as it will have a more accurate model.\n",
        "\n",
        "There is also no validation set due to the same reason as well.\n",
        "\n",
        "However, the reason why 100% dataset is not being used for training the model is because it needs to be test to ensure it is up to a good enough standard in terms of the given metric (which is specified during the Model Evaluation)."
      ],
      "metadata": {
        "id": "MxtTI5685A1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Shuffle the dataset and then Split the dataset into the training and the testing sets.\n",
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "train_df, test_df = df[:int(0.8*df.shape[0])], df[int(0.8*df.shape[0]):]\n",
        "\n",
        "#Select the target variable for the regression model.\n",
        "names = [t for t in df if t != 'cnt' and t != 'temp' and t != 'atemp']\n",
        "test_input, test_target = test_df[names], test_df['cnt']\n",
        "train_input, train_target = train_df[names], train_df['cnt']"
      ],
      "metadata": {
        "id": "CVgCyS6C5ZeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Training and Evaluation\n",
        "In the next Code Block, a Decision Tree model as well as a Lasso (Linear Regression) model will be implemented. These are used as a baseline to compare to a version of each model with tuned parameters.\n",
        "\n",
        "The Decision Tree model has been chosen because the model .\n",
        "\n",
        "The Lasso model has been chosen because due to the target variable (cnt) containing a continuous data type and having a linear trend. The Lasso model also allows for the identification of sparse coefficients for each column/attribute in the dataset. However, it needs to be used 'on top of' a regression model (in this case a linear regression model).\n",
        "\n",
        "The Root Mean Square Error has been chosen due to averaging the error of the model and then scaling it to the range of the target variable. For the purpose of having the error as a percentage between 0 and 1, the error is normalized using the test_target's minimum and maximum."
      ],
      "metadata": {
        "id": "4r0CcArBLIhj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_error = []\n",
        "for m in [Lasso, DecisionTreeClassifier]:\n",
        "  #Build and train the model.\n",
        "  model = m()\n",
        "  model.fit(train_input, train_target)\n",
        "\n",
        "  #Calculate the root mean square error (RMSE) using the mean squared error metric from sklearn.\n",
        "  results = model.predict(test_input)\n",
        "  results = mse(test_target, results)\n",
        "  results = pow(results, 1/2)\n",
        "\n",
        "  #Store the normalized error (using the minimum and maximum values of the test targets).\n",
        "  base_error.append((results - test_target.min())/ (test_target.max() - test_target.min()))\n",
        "  print(base_error[len(base_error)-1])"
      ],
      "metadata": {
        "id": "wMVWrYA1XWRD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93fbe6d2-908b-4624-c337-183dc8a836f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.13298189905639743\n",
            "0.16414371209892342\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the next Code Block, the above models will be implemented with automatically tuned parameters to be compared against their baseline models using a grid search method. This method of optimizing the hyperparameters has been chosen as it takes in the specified parameters such as the max depth of the Decision Tree and tries each permutation of their given values. It also trains the model using these parameters which another method such as RandomizedSearchCV does not do."
      ],
      "metadata": {
        "id": "msD1C1nY0y3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Run the parameter tuning on the DecisionTreeClassifier object.\n",
        "tuned_parameters = [{\"criterion\": [\"gini\", \"entropy\"], \"max_depth\": [2, 3, 4, 5, 6, 7, 8, 9, 10]},]\n",
        "model = DecisionTreeClassifier()\n",
        "\n",
        "grid_search = GridSearchCV(model, tuned_parameters, scoring=\"neg_root_mean_squared_error\", cv=5)\n",
        "grid_search.fit(train_input, train_target)\n",
        "\n",
        "print(\"Best parameters (Decision Tree):\", grid_search.best_params_)\n",
        "\n",
        "#Run the parameter tuning on the LogisticRegression object.\n",
        "tuned_parameters = [{\"alpha\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]},]\n",
        "model = Lasso()\n",
        "\n",
        "grid_search = GridSearchCV(model, tuned_parameters, scoring=\"neg_root_mean_squared_error\", cv=5)\n",
        "grid_search.fit(train_input, train_target)\n",
        "\n",
        "print(\"Best parameters (Lasso):\", grid_search.best_params_)"
      ],
      "metadata": {
        "id": "v9GB3rMS2NSr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c32580c4-8d72-4751-c1ab-4c7b9a4d2b78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters (Decision Tree): {'criterion': 'gini', 'max_depth': 4}\n",
            "Best parameters (Lasso): {'alpha': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the best parameters for each regression technique, the following code block will construct and train the models and then calculate the root mean squared error (RMSE) to compare them to the baselines of these models."
      ],
      "metadata": {
        "id": "Ko5MXIATVXHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This stores the average errors of the \"optimized\" model's errors.\n",
        "optimized_error = []\n",
        "\n",
        "#Generate, train and test the Lasso method.\n",
        "model = Lasso(alpha=1)\n",
        "model.fit(train_input, train_target)\n",
        "\n",
        "#Calculate the root mean square error (RMSE) using the mean squared error metric from sklearn.\n",
        "results = model.predict(test_input)\n",
        "results = mse(test_target, results)\n",
        "results = pow(results, 1/2)\n",
        "\n",
        "#Store the normalized error (using the minimum and maximum values of the test targets).\n",
        "optimized_error.append((results - test_target.min())/ (test_target.max() - test_target.min()))\n",
        "print(optimized_error[len(optimized_error)-1])\n",
        "\n",
        "#Generate, train and test the Decision Tree method.\n",
        "model = DecisionTreeClassifier(criterion=\"gini\", max_depth=5)\n",
        "model.fit(train_input, train_target)\n",
        "\n",
        "#Calculate the root mean square error (RMSE) using the mean squared error metric from sklearn.\n",
        "results = model.predict(test_input)\n",
        "results = mse(test_target, results)\n",
        "results = pow(results, 1/2)\n",
        "\n",
        "#Store the normalized error (using the minimum and maximum values of the test targets).\n",
        "optimized_error.append((results - test_target.min())/ (test_target.max() - test_target.min()))\n",
        "print(optimized_error[len(optimized_error)-1])"
      ],
      "metadata": {
        "id": "n64vHz7XVtGj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1228ca6f-cd40-4efb-aa82-c51003cfbc4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.13298189905639743\n",
            "0.15150251384750202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following Code Block, the baseline models will be compared to their optimized counterparts."
      ],
      "metadata": {
        "id": "1vpOUlXY2diN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if optimized_error[0] < base_error[0]:\n",
        "  print(\"Baseline Lasso is better by {diff}.\".format(diff=abs(optimized_error[0] - base_error[0])))\n",
        "else:\n",
        "  print(\"Optimized Lasso is better by {diff}.\".format(diff=abs(optimized_error[0] - base_error[0])))\n",
        "\n",
        "if optimized_error[1] < base_error[1]:\n",
        "  print(\"Baseline Decision Tree is better by {diff}.\".format(diff=abs(optimized_error[1] - base_error[1])))\n",
        "else:\n",
        "  print(\"Optimized Decision Tree is better by {diff}.\".format(diff=abs(optimized_error[1] - base_error[1])))"
      ],
      "metadata": {
        "id": "zvei2x7t2_fJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04898a20-fca5-49a8-cae7-44f87f493a92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized Lasso is better by 0.0.\n",
            "Baseline Decision Tree is better by 0.012641198251421404.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Conclusion\n",
        "Looking at the results of the models, it can be seen that the baseline Lasso (Linear) regression model has the same accuracy as it's optimized counterpart. This shows that in this particular instance that there is no need to optimize the hyperparameters for this model as the baseline model is as good at predicting the number of bike rentals.\n",
        "\n",
        "As for the Decision Tree, it can be seen that the optimized decision tree is marginally better (by a relatively small margin) than the baseline model. This suggests that there is no reason to spend more computational resources on optimizing this model for such a small improvement.\n",
        "\n",
        "One potential improvement would be a wider comparison of models. This would allow the relationships between the inputs and the target(s) to be viewed from a variety of angles.\n",
        "\n",
        "Another potential improvemnt would be to vary the target variables being used. In particular, the variables the discuss whether the renters are members of not of the service."
      ],
      "metadata": {
        "id": "IT75ao933ACQ"
      }
    }
  ]
}